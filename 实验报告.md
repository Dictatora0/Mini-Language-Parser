# Mini 语言语法分析器实验报告

## 实验基本信息

**实验题目**：Mini 语言语法分析器的设计与实现

**实验目的**：

1.  掌握递归下降分析法的基本原理和实现方法。
2.  理解并设计 LL(1) 文法，消除左递归和提取左公因子。
3.  实现从 Token 流到抽象语法树（AST）的构建过程。
4.  设计并实现语法分析中的错误检测与恢复机制。
5.  理解编译器前端中词法分析、语法分析与语义分析的接口关系。

**实验环境**：

- 编程语言：Python 3.x
- 开发工具：VSCode
- 操作系统：macOS / Linux

---

## 第一部分 语言语法规则

本项目实现的 Mini 语言是一种类 Pascal 的命令式编程语言，支持变量声明、赋值、条件与循环控制结构、算术与逻辑运算、基本输入输出功能。

### 1.1 程序结构

Mini 程序由三部分组成：程序头、可选的变量声明区、语句块。程序以 `program` 关键字开头，后跟程序名和分号，最后以语句块和点号结束。变量声明区以 `var` 关键字引导，可声明整数类型、实数类型、布尔类型和字符串类型变量。语句块由 `begin` 和 `end` 包围，内部可包含多条语句，语句之间用分号分隔。

### 1.2 数据类型与字面量

语言支持四种基本数据类型：整数类型（`integer`）、实数类型（`real`）、布尔类型（`boolean`）和字符串类型（`string`）。整数字面量由数字序列组成，实数字面量包含小数点和小数部分，布尔字面量为 `true` 或 `false`，字符串字面量用单引号或双引号包围。标识符由字母、数字和下划线组成，首字符必须是字母或下划线。

### 1.3 运算符

算术运算符包括加（`+`）、减（`-`）、乘（`*`）、除（`/`），遵循标准运算优先级。关系运算符有小于（`<`）、小于等于（`<=`）、大于（`>`）、大于等于（`>=`）、等于（`=`）、不等于（`<>`）。逻辑运算符包括与（`and`）、或（`or`）、非（`not`）。一元负号可用于数值表达式前。

### 1.4 语句类型

赋值语句使用 `:=` 运算符，将表达式的值赋给变量。条件语句为 `if` 条件 `then` 语句 `else` 语句的形式，其中 `else` 部分可省略，条件必须是布尔表达式。循环语句为 `while` 条件 `do` 语句的形式，条件为真时重复执行语句体。语句块可嵌套使用 `begin...end`，实现多条语句的复合。输出语句 `write(表达式)` 将表达式值输出，输入语句 `read(变量)` 从标准输入读取值到指定变量。

### 1.5 表达式结构

表达式按优先级从低到高分为逻辑或表达式、逻辑与表达式、逻辑非表达式、关系表达式、算术表达式。算术表达式由加减项组成，项由乘除因子组成。因子可以是数字、字符串、布尔值、变量、带括号的表达式或一元运算表达式。表达式支持任意深度的括号嵌套，运算符结合性遵循数学惯例。

### 1.6 注释

语言支持两种注释：单行注释以 `//` 开头至行尾，块注释用 `{` 和 `}` 包围。注释在词法分析阶段被跳过，不影响程序语义。

---

## 第二部分 文法定义

以下文法使用扩展巴科斯范式（EBNF）描述，其中 `::=` 表示定义，`|` 表示或，`[]` 表示可选，`{}` 表示零次或多次重复。

### 2.1 程序结构

```ebnf
<program> ::= "program" IDENTIFIER ";" [<var_declarations>] <block> "."

<var_declarations> ::= "var" <var_decl> {";" <var_decl>} ";"

<var_decl> ::= IDENTIFIER {"," IDENTIFIER} ":" <type>

<type> ::= "integer" | "real" | "boolean" | "string"

<block> ::= "begin" <statement_list> "end"

<statement_list> ::= <statement> {";" <statement>}
```

### 2.2 语句

```ebnf
<statement> ::= <assignment_stmt>
              | <if_stmt>
              | <while_stmt>
              | <write_stmt>
              | <read_stmt>
              | <block>
              | ε

<assignment_stmt> ::= IDENTIFIER ":=" <expression>

<if_stmt> ::= "if" <condition> "then" <statement> ["else" <statement>]

<while_stmt> ::= "while" <condition> "do" <statement>

<write_stmt> ::= "write" "(" <expression> ")"

<read_stmt> ::= "read" "(" IDENTIFIER ")"
```

### 2.3 条件与表达式

```ebnf
<condition> ::= <or_term> {"or" <or_term>}

<or_term> ::= <and_term> {"and" <and_term>}

<and_term> ::= <not_term>

<not_term> ::= ["not"] <comparison>

<comparison> ::= <expression> <relop> <expression>
               | "(" <condition> ")"

<relop> ::= "<" | "<=" | ">" | ">=" | "=" | "<>"

<expression> ::= <term> {("+" | "-") <term>}

<term> ::= <factor> {("*" | "/") <factor>}

<factor> ::= IDENTIFIER
           | INTEGER
           | REAL
           | STRING
           | "true" | "false"
           | "(" <expression> ")"
           | "-" <factor>
```

### 2.4 词法单元

```ebnf
IDENTIFIER ::= (letter | "_") {letter | digit | "_"}

INTEGER ::= digit {digit}

REAL ::= digit {digit} "." digit {digit}

STRING ::= '"' {character} '"' | "'" {character} "'"

letter ::= "a".."z" | "A".."Z"

digit ::= "0".."9"
```

---

## 第三部分 语法分析算法

本语法分析器采用递归下降分析算法，基于 LL(1) 文法设计，手工实现了完整的自顶向下解析过程。

### 3.1 算法类型与核心思想

本项目采用的语法分析算法属于典型的 LL(1) 递归下降分析。其基本思想是：对文法中的每一个非终结符，编写一个具有相同含义的解析函数，使程序结构在宏观上与文法产生式形成一一对应关系。每个解析函数在被调用时，根据当前输入 Token 的类型选择相应的产生式分支，在匹配到终结符或子非终结符后，再递归调用下一级解析函数；当所有产生式右部依次匹配成功时，即完成了对该非终结符对应语法片段的识别。

在具体实现层面，`ASTParser` 以 `<program>` 为起始符号：`parse()` 作为统一入口，仅负责调用 `program()` 并在分析结束后检查是否已经读到 `EOF`，真正的推导从 `program()` 开始展开。`program()` 按顺序识别 `program` 关键字、程序名和分号，然后视情况进入变量声明部分 `var_declarations()`，再进入语句块 `block()`；语句层面由 `statement()` 统一分发到赋值、条件、循环、块以及输入输出等不同分支；表达式和条件部分则通过 `expression`、`term`、`factor` 以及 `condition`、`or_term`、`and_term`、`not_term`、`comparison` 等一组互相调用的函数体现运算优先级和布尔逻辑的层次结构。整个分析过程自顶向下、从左到右地一次性消费 Token 流，不依赖回溯，而是依托于 LL(1) 文法的设计和对当前 Token 类型的预测性判断来保证解析的确定性。

### 3.2 主要数据结构

在具体实现中，`ASTParser` 的构造函数接收词法分析阶段产生的 Token 序列以及原始源代码字符串，并在此基础上初始化若干与语法分析过程紧密相关的状态量。Token 序列中的每个 Token 记录了类型、词素值以及所在的行列位置，解析器通过整型下标 `pos` 和引用 `current_token` 指向当前待分析的符号，`advance()` 用于推进 `pos` 并同步更新 `current_token`，`peek()` 则在不消费输入的前提下向前查看后续 Token，为少量前瞻判断提供支持。

为了便于错误报告和调试，解析器在初始化时还会把源代码拆分为按行存储的 `source_lines`。`error()` 方法在记录错误时，会查找当前 Token 所在的源代码行，构造带有上下文代码和指示箭头的 `ParseError` 对象，并把格式化后的错误字符串写入 `errors` 列表，同时将 `success` 标记为 `False`。这样既能在一次分析过程中累积多个错误，也方便在命令行界面上直接输出清晰的错误信息。

抽象语法树（AST）由 `ast_nodes.py` 中定义的一组节点类表示，包括 `Program`、`Block`、`VarDeclarations`、`VarDecl`、`Assignment`、`IfStatement`、`WhileStatement`、`WriteStatement`、`ReadStatement` 以及 `BinaryOp`、`UnaryOp`、`Number`、`String`、`Boolean`、`Variable` 等。解析函数在识别出相应的语法结构后，会即时构造对应的节点实例，并将源代码中的行列位置一并记录到节点上，为后续的语义分析和错误定位提供精确的位置信息。

符号表由 `ScopedSymbolTable` 负责维护。解析变量声明产生式 `<var_declarations>` 时，解析器会根据变量名和类型构造 `VarDecl` 节点，同时调用符号表的 `define` 方法，将变量名、类型以及声明位置包装成 `Symbol` 条目写入当前作用域。当前版本主要使用全局作用域，但符号表本身已经支持多层嵌套作用域，为未来扩展局部变量、过程或函数声明预留了空间。与此同时，解析器还维护了 `recursion_depth`、`nesting_depth` 和 `expression_depth` 等计数器以及相应的检查函数，用于在需要时限制语法分析的最大递归层次和嵌套深度。

为了便于一目了然地把握实现细节，表 1 对 `ASTParser` 中与语法分析直接相关的核心成员和辅助函数做了一个小结。

表 1 ASTParser 关键成员与辅助方法（节选）

| 名称               | 类型或归属                    | 作用                                                                    |
| ------------------ | ----------------------------- | ----------------------------------------------------------------------- |
| `tokens`           | 成员变量（List[Token]）       | 保存词法分析得到的 Token 流，是语法分析的输入                           |
| `source_code`      | 成员变量（str）               | 原始源代码字符串，用于错误信息中回显源码行                              |
| `pos`              | 成员变量（int）               | 当前解析位置在 Token 列表中的下标                                       |
| `current_token`    | 成员变量（Token）             | 当前正在查看的 Token，所有判断和匹配都基于它                            |
| `errors`           | 成员变量（List[str]）         | 记录格式化后的语法错误信息                                              |
| `success`          | 成员变量（bool）              | 标记本次解析是否总体成功                                                |
| `symbol_table`     | 成员变量（ScopedSymbolTable） | 保存变量声明信息，为语义分析和解释器提供基础                            |
| `advance()`        | 成员方法                      | `pos += 1` 并更新 `current_token`，向前移动一个 Token                   |
| `peek(offset)`     | 成员方法                      | 只查看不消费后续 Token，用于少量前瞻判断                                |
| `check(*types)`    | 成员方法                      | 判断 `current_token` 的类型是否在给定集合中，但不前进                   |
| `match(*types)`    | 成员方法                      | 在类型匹配时消费当前 Token 并前进一位，返回是否匹配                     |
| `expect(type,msg)` | 成员方法                      | 期望特定 Token；若不满足则调用 `error()` 记录错误并返回 `None`          |
| `error(message)`   | 成员方法                      | 基于当前 Token 和源码行构造 `ParseError`，并写入 `errors` 列表          |
| `synchronize(...)` | 成员方法                      | 出错后跳过 Token 直到遇到同步集中符号，用于错误恢复                     |
| `parse()`          | 成员方法                      | 从 `<program>` 开始驱动整个语法分析过程，返回根节点 `Program` 或 `None` |
| `get_result()`     | 成员方法                      | 在仅根据 Token 文件解析时，汇总并返回本次语法检查的结果字符串           |

这些成员和方法构成了递归下降分析的“工作台”，后续的 `program()`、`statement()` 等高层解析函数都依赖它们完成具体的匹配和错误处理。

### 3.3 解析函数与产生式对应

语法分析器类 `ASTParser` 中的每个解析方法基本上都可以一一对应到文法中的某个非终结符，这也是递归下降方法直观易懂的根源所在。在最外层，`parse()` 作为统一入口，仅负责调用 `program()` 并在分析结束后检查是否已经到达 `EOF`，真正的文法推导则从 `program()` 开始展开。

`program()` 对应 `<program>` 产生式，按照固定顺序期望出现 `program` 关键字、程序名标识符和分号；随后根据是否读到 `var` 关键字决定是否进入 `<var_declarations>` 分支，最后依次解析语句块 `<block>` 和结束点号 `.`，并在一切就绪时构造 `Program` 根节点。在变量声明部分，`var_declarations()` 按行读取逗号分隔的标识符序列，随后期望一个冒号和类型关键字（`integer`、`real`、`boolean` 或 `string`），据此为每个变量构造 `VarDecl` 节点并写入符号表；若同一标识符在同一作用域内被重复声明，则通过符号表的 `define` 方法返回值检测到冲突，并调用 `error()` 记录“变量重复声明”的错误信息。

`statement()` 是单条语句的分发中心，它通过 `check()` 查看当前 Token 的类型：若为标识符则进入 `assignment_stmt()`，若为 `if` 或 `while` 分别进入条件语句和循环语句的解析分支，若为 `begin` 则进入复合语句块 `block()`，若为 `write` 或 `read` 则进入输入输出语句的处理逻辑；当遇到 `end` 或分号时，则认为当前位置是一个空语句，并返回 `EmptyStatement` 节点。与之配套的 `statement_list()` 按照 `<statement_list> ::= <statement> {";" <statement>}` 的形式工作：先解析一条语句并加入列表，然后在读到分号时循环尝试解析后续语句；如果在分号之后立即看到了 `end`，则不再继续递归调用 `statement()`，从而既允许最后一条语句前没有分号，也允许在 `end` 之前出现一个多余的结尾分号，这一点在实际测试用例中得到了验证。

表达式相关的产生式则通过一组层次分明的函数来实现。`expression()` 负责处理加减运算，先调用 `term()` 得到一个项作为左操作数，在读到 `+` 或 `-` 时不断消费后续的项，并在每次循环中构造一个新的 `BinaryOp` 节点，从而体现了加减运算的左结合性。`term()` 采用类似方式处理乘除运算，只是运算符集合换成了 `*` 和 `/`，而最底层的 `factor()` 则识别标识符、各类常量、括号表达式以及一元负号表达式，再根据不同情况返回 `Variable`、`Number`、`String`、`Boolean` 或 `UnaryOp` 等节点。

条件和表达式子系统内部也形成了一条自顶向下的调用链：`condition()` 负责解析整体布尔表达式，它依次调用 `or_term()`、`and_term()` 和 `not_term()`，在 `not_term()` 中进一步下沉到 `comparison()`；`comparison()` 要么识别带关系运算符的比较式，要么在括号中再次递归调用 `condition()`，否则就回落到数值表达式层次，交给 `expression()` / `term()` / `factor()` 组合完成解析。这样一条从条件到算术表达式的调用路径，把布尔逻辑和算术计算自然地串在了一起，同时又保持了各层次的职责清晰。

### 3.4 预测分析机制

递归下降分析在不回溯的前提下，要想保持解析过程的确定性，文法必须满足 LL(1) 性质，即对于每个非终结符的多个产生式，其 FIRST 集在首符号上互不相交，仅靠向前看一个 Token 就能唯一决定应当选择哪一条产生式。在本实现中，这一“预测过程”并没有显式地构造 FIRST 集，而是以内嵌的方式体现在各个解析函数对 `check()` 和 `match()` 的调用顺序上：对于同一非终结符的多个候选分支，只要当前 Token 的类型落在某个分支对应的首符号集合中，就进入该分支，否则认为该分支不适用。

`check()` 方法用于查看当前 Token 的类型是否属于给定集合而不消费输入，`match()` 则在类型匹配时完成检查与前进两步操作；对于必须出现的关键字或符号，则使用 `expect()` 进行“强制匹配”，一旦不满足就调用 `error()` 记录错误并在必要时通过 `synchronize()` 进行错误恢复。三者结合起来，在正常路径上实现了 LL(1) 风格的预测分析，在异常路径上则为错误定位和恢复提供了统一的接口。

以 `statement()` 为例，其分支选择逻辑如下：

```python
if self.check(TokenType.IDENTIFIER):
    return self.assignment_stmt()
elif self.check(TokenType.IF):
    return self.if_stmt()
elif self.check(TokenType.WHILE):
    return self.while_stmt()
```

这里不同的首符号集合隐含地扮演了 FIRST 集的角色：以 `IDENTIFIER` 开头的语句被判定为赋值语句，以 `IF` 或 `WHILE` 开头的语句分别被判定为条件语句和循环语句，以 `BEGIN`、`WRITE`、`READ` 开头的语句则由其它分支处理。由于这些集合在文法设计时已经避免了交叉，解析器在遇到任意一个合法的语句起始符号时，都能够通过一次 `check()` 判断唯一确定应当调用的解析函数，从而在无需回溯的前提下完成整个语法分析过程。

### 3.5 算法流程示例

以解析赋值语句 `x := 10 + y` 为例：

1. `statement()` 识别当前 Token 为 `IDENTIFIER`，调用 `assignment_stmt()`
2. `assignment_stmt()` 消费标识符 `x`，期望并消费 `:=`，调用 `expression()`
3. `expression()` 调用 `term()` 获取左项
4. `term()` 调用 `factor()`，识别整数 `10`，返回 `Number` 节点
5. `term()` 返回后，`expression()` 检测到 `+`，消费该符号，再次调用 `term()`
6. `term()` 调用 `factor()`，识别标识符 `y`，返回 `Variable` 节点
7. `expression()` 构建 `BinaryOp(left=Number(10), op=+, right=Variable(y))` 返回
8. `assignment_stmt()` 构建 `Assignment(variable='x', expression=BinaryOp(...))` 返回

整个过程无需回溯，一次扫描完成解析和 AST 构建。

### 3.6 边界条件控制

为防止恶意输入或错误程序导致解析器崩溃，实现中设置了多项边界检查：

- 递归深度限制 100 层（`MAX_RECURSION_DEPTH`），防止栈溢出
- 嵌套深度限制 50 层（`MAX_NESTING_DEPTH`），防止过深的语句块嵌套
- 表达式深度限制 50 层（`MAX_EXPRESSION_DEPTH`），防止过深的表达式嵌套

虽然当前代码中声明了这些检查函数（`check_recursion_depth`、`check_nesting_depth`、`check_expression_depth`），但主要解析流程中未实际调用，主要依靠 Python 解释器的默认栈限制。这些预留接口为未来增强鲁棒性提供了扩展点。

### 3.7 与词法分析、语义分析和解释器的衔接

从整体架构看，语法分析器既是编译前端的中枢，也是各个阶段之间的“分界线”。结合 `src` 目录下的实现，可以把各阶段的职责概括为：

- 词法分析阶段：`lexer.Lexer` 读取源代码字符流，生成带有类型和位置的 Token 序列，并在发现非法字符、过长标识符或未闭合字符串时产生词法错误。
- 语法分析阶段：`parser_ast.ASTParser` 消费 Token 序列，按照 LL(1) 文法构建 AST 和符号表，并通过 `ParseError` 统一报告语法错误。
- 语义分析阶段：`semantic_analyzer.SemanticAnalyzer` 在 AST 和符号表上进行类型检查和语义验证，发现未声明变量、类型不匹配、非法运算等问题。
- 解释执行阶段：`interpreter.Interpreter` 在语义检查通过的前提下遍历 AST，执行赋值、条件、循环和 I/O 操作，形成最终变量状态和输出结果。

这几个阶段通过 `parse_to_ast()` 和 `run_program()` 等接口串联起来：

- 用户或测试代码首先调用 `parse_to_ast()`，该函数内部依次调用 `Lexer` 和 `ASTParser`，并在可选条件下调用语义分析器。
- 语法分析成功且无语义错误时，可以使用 `ASTPrinter` 将语法树和符号表打印出来，用于教学展示或调试。
- 若需要执行程序，则调用 `run_program()`，其中再次调用 `parse_to_ast()` 获取 AST 和符号表，再由解释器负责真正的执行。

从 `main.py` 的主流程来看，典型的调用关系可以用文字概括为：

- `analyze_source_file()`：读取源文件内容 → 调用 `parse_from_source(source_code)` → 内部调用 `parse_to_ast(..., enable_semantic_check=False)` → 由 `ASTParser.parse()` 完成语法分析，返回结果字符串供命令行打印。
- `run_demo()`：准备若干内嵌示例程序 → 对每个示例调用 `parse_from_source()` → 语法分析流程与上面一致，用于展示不同输入下的分析结果。
- `main()` 其他分支（如 `--test`）：通过测试模块 `tests.test_cases.run_all_tests()` 间接多次调用 `parse_from_source()`，系统性验证语法分析器在各种正确和错误程序上的行为。

得益于这种清晰的分层设计，语法分析器只关注“结构是否符合文法”，而不直接干预类型检查和运行时行为；语义分析器和解释器则在 AST 之上工作。这一划分既符合编译原理课程中“词法—语法—语义—执行”逐层细化的思路，也方便在实验中分别测试和展示各个阶段的效果。

---

### 3.8 例子：从 AST 到语义分析再到解释执行

为了更直观地说明各个阶段之间的衔接，本节以 `demo_ast.py` 中的阶乘程序为例，串联 AST 生成、语义分析和解释执行的全过程。示例程序如下：

```pascal
program factorial;
var
    n, fact : integer;
begin
    n := 5;
    fact := 1;
    while n > 0 do
    begin
        fact := fact * n;
        n := n - 1
    end
end.
```

在这个阶乘示例中，首先由 `demo_ast.py` 调用 `parse_to_ast(source_code)`，内部依次执行词法分析和语法分析，最终得到一棵以 `Program` 为根节点的抽象语法树。根节点下面的 `var_declarations` 记录了 `n: integer` 和 `fact: integer` 两个变量声明，`block` 节点则包含对这两个变量的初始化语句以及一个 `WhileStatement` 循环语句，其循环条件为关系表达式 `n > 0`，循环体内部依次对 `fact` 进行乘法累积并将 `n` 递减直至条件不再满足。借助 `print_ast(ast)` 可以直观地看到这一树形结构及其嵌套关系。

在语法分析成功的前提下，`var_declarations()` 已经将 `n` 和 `fact` 以 `Symbol` 的形式写入 `ScopedSymbolTable`，类型均为 `INTEGER`。`parse_to_ast()` 随后调用 `analyze_semantics(ast, symbol_table)`，由 `SemanticAnalyzer` 从 `Program` 节点出发遍历整棵语法树：在 `visit_Assignment` 中，它根据赋值左侧变量名从符号表查找预期类型，再利用 `get_expression_type` 推导右侧表达式类型，并借助 `can_convert` 判断是否允许隐式转换；在 `visit_WhileStatement` 中，则通过 `get_expression_type(node.condition)` 检查循环条件是否为 `BOOLEAN` 类型。对于当前程序，所有赋值语句和条件表达式都满足类型规则，因此语义分析阶段不会产生错误。

在此基础上，`demo_features_comparison()` 还调用 `run_program(source_code)` 对同一源程序进行解释执行。`run_program` 内部再次使用 `parse_to_ast` 获取 AST 和符号表，在确认不存在语法和语义错误后，构造 `Interpreter` 并调用其 `interpret(ast)`。解释器在一个全局字典 `global_scope` 中维护运行时变量值，按照 AST 的结构依次执行初始化赋值和循环体语句：程序开始时 `n = 5`、`fact = 1`，每次循环将 `fact` 更新为 `fact * n`，再将 `n` 减一，直至条件 `n > 0` 不再成立。执行结束后，`run_program` 返回的 `final_state` 中，`fact` 的值为 `120.0`，`n` 的值为 `0.0`，并同时生成一段格式化的结果字符串列出所有变量的最终值。

这一示例清楚地展示了各个阶段之间的衔接关系：语法分析负责把源代码组织成结构化的 AST，语义分析在 AST 和符号表的基础上完成类型一致性检查，而解释器则在同一棵 AST 上驱动程序执行。三者以 AST 和符号表为纽带，构成了一个完整而清晰的 Mini 语言前端与执行环境。

### 3.9 语义分析与类型规则概述

语义分析阶段的主要任务是确保那些在语法层面已经被判定为“形式正确”的程序，在类型系统和运算语义上同样是自洽的。结合 `SemanticAnalyzer.get_binary_op_type` 及其调用的辅助函数，可以将当前实现中采用的主要类型规则概括如下：

1. **基本表达式类型**：

   - 数字字面量：根据数值是否为整数，推导为 `INTEGER` 或 `REAL`，从而区分整数类型和实数类型常量。
   - 字符串字面量：统一视为 `STRING` 类型。
   - 布尔字面量：对应 `BOOLEAN` 类型。
   - 变量引用：根据变量名在符号表中查找其声明的类型；若符号不存在，则报告“变量未声明”的语义错误。

2. **赋值语句类型检查**：

   - 在 `visit_Assignment` 中，首先根据左侧变量名从符号表中取出其声明类型，然后调用 `get_expression_type` 推导右侧表达式的静态类型。
   - 解析器通过 `can_convert(from_type, to_type)` 判断赋值是否允许隐式转换：同类型之间的赋值总是被接受（如 `INTEGER` 赋给 `INTEGER`），此外还允许将 `INTEGER` 隐式转换为 `REAL`，从而支持将整数表达式赋值给实数类型的变量。
   - 对于其他不兼容的组合（例如将 `STRING` 赋给 `INTEGER` 变量，或将 `BOOLEAN` 赋给数值变量），语义分析器会统一报告“类型不匹配”的错误信息。

3. **算术运算符（+、-、\*、/）**：

   - 在 `get_binary_op_type` 中，若运算符属于加减乘除，语义分析器要求左右操作数都为数值类型（`INTEGER` 或 `REAL`）；否则会给出诸如“算术运算左/右操作数必须是数值类型”的错误提示。
   - 在操作数类型合法的前提下，调用 `binary_op_result_type(left_type, op_str, right_type)` 推导结果类型：若任一操作数为 `REAL`，结果提升为 `REAL`，否则结果保持为 `INTEGER`。

4. **关系运算符（<、<=、>、>=、=、<>）**：

   - 对于所有关系运算符，当前实现要求两侧操作数均为可比较的数值类型（`INTEGER` 或 `REAL`），否则报告“关系运算左右操作数必须是数值类型”的语义错误。
   - 一旦操作数类型满足要求，关系运算的结果类型统一为 `BOOLEAN`。

5. **逻辑运算符（and、or、not）**：

   - 对于二元逻辑运算 `and` 和 `or`，语义分析器要求左右两侧操作数均为 `BOOLEAN` 类型，否则分别报告左右操作数必须是 `BOOLEAN` 的语义错误。
   - 对于一元逻辑非 `not`，则要求其唯一操作数为 `BOOLEAN`；若类型不符，同样会产生带有详细说明的错误提示。
   - 在类型满足约束的情况下，逻辑运算的结果类型始终为 `BOOLEAN`。

6. **条件表达式类型**：
   - 在 `visit_IfStatement` 和 `visit_WhileStatement` 中，语义分析器要求条件表达式类型为 `BOOLEAN`，否则会给出“if/while 语句的条件必须是 boolean 类型，但得到 …”的错误信息。

综合来看，语义分析阶段在语法树的基础上引入了静态类型检查：既保证赋值方向的类型兼容性，又保证算术、关系和逻辑运算的操作数类型合理，还规定了 if/while 条件表达式必须为布尔类型。这样一来，即便某些程序在语法上是“合法”的，也会因为类型不一致或运算不合理而在语义阶段被拦截，从而提高了 Mini 语言程序的安全性和可预期性。

---

## 第四部分 出错处理策略

本语法分析器实现了完善的错误检测与部分错误恢复机制，既能准确报告错误位置和类型，又能在遇到错误后继续分析，发现更多潜在错误。

### 4.1 错误检测机制

**期望匹配检查**：`expect()` 方法用于检查当前 Token 是否为期望类型。若不匹配，记录错误信息并返回 `None`。例如在解析程序头时，`expect(TokenType.PROGRAM)` 检查是否以 `program` 开头，若不是则报错"程序必须以 'program' 关键字开头"。

**语法结构检查**：各解析函数在适当位置插入检查逻辑。例如 `if_stmt()` 在解析条件后检查是否有 `then`，若无则报错"if 语句缺少 'then'"。`assignment_stmt()` 在标识符后检查 `:=`，若为 `=` 则报错"赋值语句缺少 ':=' 运算符"。

**表达式完整性检查**：`expression()` 和 `term()` 在遇到运算符后调用下一层解析函数，若返回 `None` 则报错。例如"运算符 '+'/'-' 后缺少项"、"运算符 '\*'/'/' 后缺少因子"。

**括号匹配检查**：`factor()` 和 `comparison()` 在遇到左括号后解析表达式，若未找到右括号则报错"表达式缺少右括号 ')'"。

### 4.2 错误信息格式

错误信息通过 `ParseError` 类封装，包含错误描述、Token 位置、源代码行。`format_error()` 方法生成格式化的错误输出：

```
语法错误 [行4:列26]: if 语句缺少 'then'
  if x > 0
           ^
```

第一行给出行列位置和错误描述，第二行显示源代码内容，第三行用 `^` 指向错误位置。这种可视化输出大大提高了错误定位的直观性。

### 4.3 错误恢复策略

**同步集（Synchronizing Set）恢复**：`synchronize()` 方法实现了经典的同步集恢复技术。当检测到错误后，跳过后续 Token 直到遇到同步集中的 Token。同步集通常包含可能的语句或语句块结束符号，如 `SEMICOLON`、`END`、`DOT`。

在 `program()` 中，若程序名后缺少分号，调用 `synchronize({TokenType.VAR, TokenType.BEGIN})` 跳过无效 Token，继续尝试解析变量声明或语句块。在 `assignment_stmt()` 中，若赋值运算符或表达式错误，调用 `synchronize({TokenType.SEMICOLON, TokenType.END})` 跳到下一条语句。

这种恢复策略的优点是可以继续分析后续代码，一次编译发现多个错误，减少反复编译的次数。缺点是可能产生级联错误，即前一个错误导致后续错误。

**函数返回 None 传播**：当子解析函数返回 `None` 表示解析失败时，上层函数可选择记录错误后继续，或直接返回 `None` 向上传播失败状态。例如 `if_stmt()` 若条件解析失败，仍会尝试解析 `then` 分支，这样可以发现 `then` 关键字是否缺失。

### 4.4 错误处理实例

**缺少分号**：

```
program err6;
begin
    x := 10
    y := 20
end.
```

解析到 `x := 10` 后，`statement_list()` 期望分号但遇到标识符 `y`。由于未匹配到 `SEMICOLON`，循环条件不满足，退出语句列表解析。随后在 `block()` 中期望 `END` 但遇到 `y`，报错"缺少 'end'"。

**括号不匹配**：

```
program err3;
begin
    y := (a + b * c
end.
```

`factor()` 识别左括号后调用 `expression()`，表达式解析完成后期望右括号，但遇到 `end`，报错"表达式缺少右括号 ')'"。随后 `assignment_stmt()` 发现表达式解析失败，报错"赋值语句右侧表达式错误"，并调用 `synchronize({TokenType.SEMICOLON, TokenType.END})` 跳到 `end`。

**多余符号**：若程序在 `end.` 之后还有内容，`parse()` 方法在成功解析后检查当前 Token 是否为 `EOF`，若不是则报错"程序结束后有多余的内容"。

### 4.5 错误处理的局限性

当前实现主要关注语法错误检测，错误恢复策略相对简单。在复杂嵌套结构中，同步集的选择可能不够精确，导致恢复后位置偏差。此外，未实现插入缺失符号的恢复策略，例如在缺少分号时自动插入分号继续解析。这些都是可以改进的方向。

---

## 第五部分 测试计划与测试报告

### 5.1 测试分类与设计

测试用例分为五类，共 29 个测试用例，覆盖语法分析器的各种场景。

**正确程序测试（10 个）**：验证语法分析器对合法程序的识别能力，包括简单赋值、条件语句、循环语句、复杂表达式、嵌套结构等。这些测试用例预期输出"该程序符合语法要求"。

**表达式错误测试（4 个）**：针对表达式的常见错误，如表达式不完整（`i := 1 +`）、缺少运算数（`x := * 5`）、括号不匹配（`y := (a + b * c`）、多余右括号（`z := a + b)`）。预期检测到相应的语法错误。

**语句错误测试（5 个）**：测试语句层面的错误，包括缺少赋值运算符（用 `=` 代替 `:=`）、缺少分号、`if` 缺少 `then`、`while` 缺少 `do`、条件表达式错误（`if x then` 缺少关系运算符）。

**结构错误测试（6 个）**：测试程序结构的必需元素，如缺少 `program` 关键字、缺少程序名、缺少 `begin`、缺少 `end`、缺少结束点、`begin-end` 不匹配。

**边界情况测试（4 个）**：测试特殊情况，包括空程序（只有 `begin end.`）、只有一条语句、末尾多余分号、深层嵌套（4 层 if 嵌套）。

### 5.2 测试执行方法

测试用例存储在 `tests/test_cases.py` 文件的 `TEST_CASES` 字典中。通过 `run_all_tests()` 函数遍历所有测试用例，对每个用例调用 `parse_from_source()` 进行解析，将实际输出与预期输出比对。对于正确程序，期望结果为"该程序符合语法要求"的精确匹配。对于错误程序，期望结果中包含特定关键字（如 "表达式错误"、"then"、"do" 等）。

运行命令为 `python3 main.py --test` 或 `make test`。

### 5.3 测试结果

经过代码修正后，所有 29 个测试用例全部通过。修正前的主要问题是语法分析器在解析过程中错误地执行了语义检查（变量声明检查），导致没有 `var` 声明的程序报"变量未声明"错误。修正后，将变量声明检查移至语义分析阶段，语法分析器仅检查程序结构是否符合文法，符合编译原理的分层设计原则。

以下是各类测试的通过情况：

| 测试类别   | 测试数量 | 通过数量 | 通过率   |
| ---------- | -------- | -------- | -------- |
| 正确程序   | 10       | 10       | 100%     |
| 表达式错误 | 4        | 4        | 100%     |
| 语句错误   | 5        | 5        | 100%     |
| 结构错误   | 6        | 6        | 100%     |
| 边界情况   | 4        | 4        | 100%     |
| **总计**   | **29**   | **29**   | **100%** |

### 5.4 典型测试用例分析

**测试用例 1：简单赋值和算术运算**

```pascal
program test1;
begin
    x := 10;
    y := 20;
    z := x + y * 2
end.
```

- 测试目的：验证基本赋值语句和混合算术运算的解析
- 实际结果：该程序符合语法要求
- 结论：通过

**测试用例 2：if-then-else 嵌套**

```pascal
program test3;
begin
    if x < y then
        z := x + y
    else
        z := x - y
end.
```

- 测试目的：验证条件语句的 else 分支解析
- 实际结果：该程序符合语法要求
- 结论：通过

**测试用例 3：while 循环与 begin-end 块**

```pascal
program test5;
begin
    i := 10;
    while i > 0 do
    begin
        sum := sum + i;
        i := i - 1
    end
end.
```

- 测试目的：验证循环语句中的复合语句块
- 实际结果：该程序符合语法要求
- 结论：通过

**测试用例 4：算术表达式不完整（错误）**

```pascal
program err1;
begin
    i := 1 +
end.
```

- 测试目的：检测表达式不完整错误
- 实际结果：语法错误 [行 5:列 17]: 表达式错误: 期望标识符、数字或表达式，但得到 'end'
- 结论：正确检测到错误，通过

**测试用例 5：缺少赋值运算符（错误）**

```pascal
program err5;
begin
    x = 10
end.
```

- 测试目的：检测赋值运算符错误（用 = 代替 :=）
- 实际结果：语法错误 [行 4:列 23]: 赋值语句缺少 ':=' 运算符
- 结论：正确检测到错误，通过

**测试用例 6：if 缺少 then（错误）**

```pascal
program err7;
begin
    if x > 0
        y := 1
end.
```

- 测试目的：检测 if 语句缺少 then 关键字
- 实际结果：语法错误 [行 5:列 25]: if 语句缺少 'then'
- 结论：正确检测到错误，通过

**测试用例 7：深层嵌套（边界）**

```pascal
program deep;
begin
    if a > 0 then
        if b > 0 then
            if c > 0 then
                if d > 0 then
                    x := 1
end.
```

- 测试目的：验证深层嵌套结构的解析能力
- 实际结果：该程序符合语法要求
- 结论：通过

### 5.5 错误检测能力评估

语法分析器对各类语法错误具有良好的检测能力：

- **结构完整性错误**：能准确检测缺少必需关键字（program、begin、end）、缺少分隔符（分号、点号）等错误
- **语句格式错误**：能检测赋值运算符错误、条件语句和循环语句的关键字缺失（then、do）
- **表达式格式错误**：能检测表达式不完整、运算数缺失、括号不匹配等错误
- **错误定位准确**：错误信息包含精确的行列位置和源代码上下文，便于快速定位问题

### 5.6 性能与鲁棒性

在测试中，语法分析器展现出良好的性能和鲁棒性：

- 对于正确程序，能一次遍历完成解析，时间复杂度为 O(n)，n 为 Token 数量
- 对于错误程序，能检测到第一个错误后继续分析，发现多个错误，提高调试效率
- 边界情况（空程序、深层嵌套）均能正确处理
- 错误恢复机制防止了单个错误导致后续所有内容报错的级联效应

### 5.7 测试覆盖度

当前测试用例已覆盖：

- 主要语句类型（赋值、if、while、块）和所有运算符（算术、关系、逻辑）
- 各种表达式嵌套层次
- 常见语法错误类型
- 边界条件与特殊情况

未覆盖的部分：

- 变量声明的各种组合（多变量声明、不同类型混合声明）
- 更复杂的逻辑表达式嵌套
- 超长标识符、超大数字等词法层边界情况
- 极深嵌套导致的资源限制情况

整体而言，测试集合已充分验证了语法分析器的核心功能和错误处理能力。

---

## 总结

本实验实现了一个功能完整、结构清晰的 Mini 语言语法分析器。通过递归下降算法，实现了基于 LL(1) 文法的自顶向下分析。语法分析器不仅能准确识别合法程序，还具备完善的错误检测和部分错误恢复能力。测试结果表明，该分析器能正确处理各类输入，包括正确程序、各种错误程序和边界情况，满足编译原理实验的要求。

### 实验心得与体会

通过本次实验，我对编译原理中的语法分析技术有了更具体的认识。

首先，从理论到实现的过程加深了我对递归下降分析法的理解。课堂上给出的产生式和推导过程，在代码中直接体现为一组互相调用的解析函数。通过实现 `program`、`statement`、`expression` 等函数，可以直观地看到 LL(1) 文法如何被映射到具体代码结构，这比单纯在纸面上推导更加具体和易于掌握。

其次，错误恢复部分暴露了实践中的难点。简单地在出错处立即返回会导致分析器很快停止工作，后续语句都无法检查。为了在一次编译中发现尽可能多的错误，需要仔细选择同步记号集，例如分号、`end`、`.` 等语句或程序边界。通过多次调整 `synchronize` 调用中的同步集，最终达到了既不过度跳过有效代码、又能顺利继续分析后续语句的效果。

再次，实验让我切身感受到分层设计的意义。语法分析器只负责判断源程序是否符合文法，语义分析器在 AST 上完成类型检查，解释器则基于同一棵 AST 执行程序逻辑。这样的划分使得各模块之间的依赖关系清晰：当需要修改变量声明规则或类型系统时，可以主要关注符号表和语义分析部分，而不必大幅改动语法分析代码。

最后，调试过程中出现的“语义错误被当作语法错误”这一问题，也提醒我在设计接口时要保持职责边界清晰。起初将“变量未声明”检查夹杂在语法分析过程中，导致测试用例难以区分“结构是否正确”和“语义是否正确”。在重新梳理 `parse_from_source` 与 `parse_to_ast` 的接口后，将变量声明检查完全交给语义分析阶段，既让测试结果更符合预期，也使整体结构更接近编译原理课程中介绍的标准编译器前端架构。

总体而言，这次实验不仅帮助我巩固了 LL(1) 文法和递归下降分析的相关知识，也让我在实际编码中体会到错误处理、模块边界和测试设计等工程问题的重要性。
